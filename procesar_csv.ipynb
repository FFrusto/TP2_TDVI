{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier  # Importar el modelo XGBoost\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np  # Para lidiar con NaNs.\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Score del modelo inicial 0.9464088135807542\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivo CSV de entrada \n",
    "archivo_entrada = \"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data.csv\"\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame\n",
    "df = pd.read_csv(archivo_entrada)\n",
    "\n",
    "# Paso la fecha a variable dia, mes, año \n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df['day'] = df['date'].dt.day\n",
    "df['month'] = df['date'].dt.month\n",
    "df['year'] = df['date'].dt.year\n",
    "df.drop(columns=[\"date\"])\n",
    "\n",
    "df.to_csv('competition_data_1.csv', index=False) \n",
    "\n",
    "del df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivo CSV de entrada \n",
    "archivo_entrada = \"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data.csv\"\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame\n",
    "df = pd.read_csv(archivo_entrada)\n",
    "\n",
    "# Separo los full_name en categorias y obtengo las dummies \n",
    "df['Categoria'] = df['full_name'].str.split(' -> ').str.get(0)\n",
    "dummies = pd.get_dummies(df['Categoria'])\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "df.to_csv('competition_data_2.csv', index=False) \n",
    "\n",
    "del df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivo CSV de entrada \n",
    "archivo_entrada = \"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data.csv\"\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame\n",
    "df = pd.read_csv(archivo_entrada)\n",
    "\n",
    "# Para las categorias binarias, reemplazo los True y False por 1 y 0\n",
    "categorical_columns_to_encode = [\"accepts_mercadopago\", \"boosted\", \"free_shipping\", \"fulfillment\", \"is_pdp\"]\n",
    "for col in categorical_columns_to_encode:\n",
    "    df[col] = df[col].replace({True: 1, False: 0})\n",
    "\n",
    "df.to_csv('competition_data_3.csv', index=False) \n",
    "\n",
    "del df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5d/4g206gss6cg3fktfbycqnb540000gn/T/ipykernel_3774/2613284890.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['warranty'][fila] = 1\n"
     ]
    }
   ],
   "source": [
    "# Archivo CSV de entrada \n",
    "archivo_entrada = \"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data.csv\"\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame\n",
    "df = pd.read_csv(archivo_entrada)\n",
    "\n",
    "# Me fijo si ofrecen algun tipo de garantía y lo reemplazo por 1 y 0\n",
    "for fila in df['warranty'].index:\n",
    "    if df['warranty'][fila] == 'Sin garant√≠a':\n",
    "        df['warranty'][fila] = 0\n",
    "    elif df['warranty'][fila] == None: \n",
    "        pass\n",
    "    else:\n",
    "        df['warranty'][fila] = 1\n",
    "\n",
    "df.to_csv('competition_data_4.csv', index=False) \n",
    "\n",
    "del df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivo CSV de entrada \n",
    "archivo_entrada = \"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data.csv\"\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame\n",
    "df = pd.read_csv(archivo_entrada)\n",
    "\n",
    "#Creo una variable que tiene el porcentaje de descuento que se le hace \n",
    "df['discount'] = (df['original_price'] - df['price']) / df['original_price']\n",
    "\n",
    "df.to_csv('competition_data_5.csv', index=False) \n",
    "\n",
    "del df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5d/4g206gss6cg3fktfbycqnb540000gn/T/ipykernel_3774/1770094589.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['listing_type_id'][fila] = 1\n",
      "/var/folders/5d/4g206gss6cg3fktfbycqnb540000gn/T/ipykernel_3774/1770094589.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['listing_type_id'][fila] = 2\n"
     ]
    }
   ],
   "source": [
    "# Archivo CSV de entrada \n",
    "archivo_entrada = \"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data.csv\"\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame\n",
    "df = pd.read_csv(archivo_entrada)\n",
    "\n",
    "#Cambio el listing_type_id por 1 y 2\n",
    "\n",
    "for fila in df['listing_type_id'].index:\n",
    "    if df['listing_type_id'][fila] == 'gold_special':\n",
    "        df['listing_type_id'][fila] = 1\n",
    "    elif df['listing_type_id'][fila] == 'gold_pro':\n",
    "        df['listing_type_id'][fila] = 2\n",
    "\n",
    "df.to_csv('competition_data_6.csv', index=False) \n",
    "\n",
    "del df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: /Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data.csv\n",
      "Score: 0.9036308985966918\n",
      "Archivo: /Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data_1.csv\n",
      "Score: 0.9036308985966918\n",
      "Archivo: /Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data_2.csv\n",
      "Score: 0.9027826439727821\n",
      "Archivo: /Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data_3.csv\n",
      "Score: 0.9040365855907356\n",
      "Archivo: /Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data_4.csv\n",
      "Score: 0.9036308985966918\n",
      "Archivo: /Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data_5.csv\n",
      "Score: 0.9025982407936712\n",
      "Archivo: /Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data_6.csv\n",
      "Score: 0.9026535617474045\n"
     ]
    }
   ],
   "source": [
    "# Lista de nombres de archivos de datos\n",
    "data_files = [\"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data.csv\", \"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data_1.csv\", \"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data_2.csv\", \"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data_3.csv\", \"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data_4.csv\", \"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data_5.csv\", \"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data_6.csv\"]\n",
    "\n",
    "for data_file in data_files:\n",
    "    # Cargar el archivo de datos\n",
    "    comp_data = pd.read_csv(data_file)\n",
    "    comp_data[\"date\"] = pd.to_datetime(comp_data[\"date\"])\n",
    "\n",
    "    # Divide la columna de fecha en día, mes y año\n",
    "    comp_data['day'] = comp_data['date'].dt.day\n",
    "    comp_data['month'] = comp_data['date'].dt.month\n",
    "    comp_data['year'] = comp_data['date'].dt.year\n",
    "\n",
    "    # Split into training and evaluation samples\n",
    "    train_data = comp_data[comp_data[\"ROW_ID\"].isna()]\n",
    "    eval_data = comp_data[comp_data[\"ROW_ID\"].notna()]\n",
    "    del comp_data\n",
    "    gc.collect()\n",
    "\n",
    "    # Dividir los datos en conjunto de entrenamiento y prueba (70% train, 30% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        train_data.drop(columns=[\"conversion\", \"ROW_ID\"]).select_dtypes(include='number'),\n",
    "        train_data[\"conversion\"],\n",
    "        test_size=0.3,  # Proporción para el conjunto de prueba\n",
    "        random_state=42  # Semilla aleatoria para reproducibilidad\n",
    "    )\n",
    "    del train_data\n",
    "    gc.collect()\n",
    "\n",
    "    # Cambiar el modelo a XGBoost\n",
    "    cls = make_pipeline(SimpleImputer(), XGBClassifier(max_depth=10, random_state=2345))\n",
    "    cls.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the evaluation set\n",
    "    eval_data = eval_data.drop(columns=[\"conversion\"])\n",
    "    eval_data = eval_data.select_dtypes(include='number')\n",
    "    y_preds = cls.predict_proba(eval_data.drop(columns=[\"ROW_ID\"]))[:, cls.classes_ == 1].squeeze()\n",
    "\n",
    "    print(f\"Archivo: {data_file}\")\n",
    "    print(f\"Score: {cls.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Estos fueron los scores obtenidos en el entrenamiento de un modelo donde se incluía cada uno de los cambios sobre el data frame individualmente. De los resultados obtenidos, podemos ver que todos mejoraron el score del modelo, salvo el 2 en el que se crean variables dummies para las categorias de los productos. \n",
    "Asi, voy a hacer un nuevo data frame que incluya todos los cambios realizados salvo el 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5d/4g206gss6cg3fktfbycqnb540000gn/T/ipykernel_3774/3693651291.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['warranty'][fila] = 1\n",
      "/var/folders/5d/4g206gss6cg3fktfbycqnb540000gn/T/ipykernel_3774/3693651291.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['listing_type_id'][fila] = 1\n",
      "/var/folders/5d/4g206gss6cg3fktfbycqnb540000gn/T/ipykernel_3774/3693651291.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['listing_type_id'][fila] = 2\n"
     ]
    }
   ],
   "source": [
    "archivo_entrada = \"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data.csv\"\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame\n",
    "df = pd.read_csv(archivo_entrada)\n",
    "\n",
    "# Paso la fecha a variable dia, mes, año \n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df['day'] = df['date'].dt.day\n",
    "df['month'] = df['date'].dt.month\n",
    "df['year'] = df['date'].dt.year\n",
    "df.drop(columns=[\"date\"])\n",
    "\n",
    "# Para las categorias binarias, reemplazo los True y False por 1 y 0\n",
    "categorical_columns_to_encode = [\"accepts_mercadopago\", \"boosted\", \"free_shipping\", \"fulfillment\", \"is_pdp\"]\n",
    "for col in categorical_columns_to_encode:\n",
    "    df[col] = df[col].replace({True: 1, False: 0})\n",
    "\n",
    "# Me fijo si ofrecen algun tipo de garantía y lo reemplazo por 1 y 0\n",
    "for fila in df['warranty'].index:\n",
    "    if df['warranty'][fila] == 'Sin garant√≠a':\n",
    "        df['warranty'][fila] = 0\n",
    "    elif df['warranty'][fila] == None: \n",
    "        pass\n",
    "    else:\n",
    "        df['warranty'][fila] = 1\n",
    "\n",
    "#Creo una variable que tiene el porcentaje de descuento que se le hace \n",
    "df['discount'] = (df['original_price'] - df['price']) / df['original_price']\n",
    "\n",
    "#Cambio el listing_type_id por 1 y 2\n",
    "for fila in df['listing_type_id'].index:\n",
    "    if df['listing_type_id'][fila] == 'gold_special':\n",
    "        df['listing_type_id'][fila] = 1\n",
    "    elif df['listing_type_id'][fila] == 'gold_pro':\n",
    "        df['listing_type_id'][fila] = 2\n",
    "\n",
    "\n",
    "\n",
    "df.to_csv('competition_data_7.csv', index=False) \n",
    "\n",
    "del df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entreno un modelo con todo el dataset nuevo \n",
    "# Load the competition data\n",
    "comp_data = pd.read_csv(\"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data_7.csv\")\n",
    "comp_data[\"date\"] = pd.to_datetime(comp_data[\"date\"])\n",
    "\n",
    "# Split into training and evaluation samples\n",
    "train_data = comp_data[comp_data[\"ROW_ID\"].isna()]\n",
    "eval_data = comp_data[comp_data[\"ROW_ID\"].notna()]\n",
    "del comp_data\n",
    "gc.collect()\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_data.drop(columns=[\"conversion\", \"ROW_ID\"]).select_dtypes(include='number'),\n",
    "    train_data[\"conversion\"],\n",
    "    test_size=0.1,  # Proporción para el conjunto de prueba\n",
    "    random_state=42  # Semilla aleatoria para reproducibilidad\n",
    ")\n",
    "del train_data\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar el modelo a XGBoost\n",
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic', seed = 2345, eval_metric = 'auc', **g)\n",
    "clf_xgb.fit(X_train, y_train, eval_set = [(X_test, y_test)], verbose = False)\n",
    "\n",
    "# cls = make_pipeline(SimpleImputer(), XGBClassifier(max_depth=10, random_state=2345))  # Usar XGBClassifier en lugar de DecisionTreeClassifier\n",
    "# cls.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the evaluation set\n",
    "eval_data = eval_data.drop(columns=[\"conversion\"])\n",
    "eval_data = eval_data.select_dtypes(include='number')\n",
    "y_preds =clf_xgb.predict_proba(eval_data.drop(columns=[\"ROW_ID\"]))[:, cls.classes_ == 1].squeeze()\n",
    "\n",
    "# Make the submission file\n",
    "submission_df = pd.DataFrame({\"ROW_ID\": eval_data[\"ROW_ID\"], \"conversion\": y_preds})\n",
    "submission_df[\"ROW_ID\"] = submission_df[\"ROW_ID\"].astype(int)\n",
    "submission_df.to_csv(\"xgboost_model_8.csv\", sep=\",\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "params = {'max_depth': list(range(1, 40)),\n",
    "          'learning_rate': uniform(scale = 0.2),\n",
    "          'gamma': uniform(scale = 2),\n",
    "          'reg_lambda': uniform(scale = 5),        # Parámetro de regularización.\n",
    "          'subsample': uniform(0.5, 0.5),          # Entre 0.5 y 1.\n",
    "          'min_child_weight': uniform(scale = 5),\n",
    "          'colsample_bytree': uniform(0.75, 0.25), # Entre 0.75 y 1.\n",
    "          'n_estimators': list(range(1, 1000))\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entreno un modelo con todo el dataset nuevo \n",
    "# Load the competition data\n",
    "comp_data = pd.read_csv(\"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data_7.csv\")\n",
    "comp_data[\"date\"] = pd.to_datetime(comp_data[\"date\"])\n",
    "\n",
    "# Split into training and evaluation samples\n",
    "train_data = comp_data[comp_data[\"ROW_ID\"].isna()]\n",
    "eval_data = comp_data[comp_data[\"ROW_ID\"].notna()]\n",
    "del comp_data\n",
    "gc.collect()\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_data.drop(columns=[\"conversion\", \"ROW_ID\"]).select_dtypes(include='number'),\n",
    "    train_data[\"conversion\"],\n",
    "    test_size=0.1,  # Proporción para el conjunto de prueba\n",
    "    random_state=42  # Semilla aleatoria para reproducibilidad\n",
    ")\n",
    "del train_data\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor valor de ROC-AUC encontrado: 0.8883394492644392\n",
      "Mejor valor de ROC-AUC encontrado: 0.8941624788503874\n",
      "Mejor valor de ROC-AUC encontrado: 0.8962621064207101\n",
      "Mejor valor de ROC-AUC encontrado: 0.8969607717231346\n",
      "Mejor valor de ROC-AUC encontrado: 0.897251024058803\n",
      "ROC-AUC: 0.89725\n",
      "Grilla: {'colsample_bytree': 0.7579620578446584, 'gamma': 0.7297041792253138, 'learning_rate': 0.021892166283765713, 'max_depth': 13, 'min_child_weight': 1.1724744683543746, 'n_estimators': 784, 'reg_lambda': 1.8656819555055764, 'subsample': 0.8630230443880356}\n",
      "Tiempo transcurrido: 30753.64494395256 segundos\n",
      "Tiempo de entrenamiento por iteración: 307.54 segundos\n"
     ]
    }
   ],
   "source": [
    "random_state = 2345\n",
    "start = time.time()\n",
    "best_score = 0\n",
    "best_estimator = None\n",
    "iterations = 100\n",
    "for g in ParameterSampler(params, n_iter = iterations, random_state = random_state):\n",
    "    clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic', seed = random_state, eval_metric = 'auc', **g)\n",
    "    clf_xgb.fit(X_train, y_train, eval_set = [(X_test, y_test)], verbose = False)\n",
    "\n",
    "    y_pred = clf_xgb.predict_proba(X_test)[:, 1] # Obtenemos la probabilidad de una de las clases (cualquiera).\n",
    "    auc_roc = sklearn.metrics.roc_auc_score(y_test, y_pred)\n",
    "    # Guardamos si es mejor.\n",
    "    if auc_roc > best_score:\n",
    "        print(f'Mejor valor de ROC-AUC encontrado: {auc_roc}')\n",
    "        best_score = auc_roc\n",
    "        best_grid = g\n",
    "        best_estimator = clf_xgb\n",
    "\n",
    "end = time.time()\n",
    "print('ROC-AUC: %0.5f' % best_score)\n",
    "print('Grilla:', best_grid)\n",
    "print(f'Tiempo transcurrido: {str(end - start)} segundos')\n",
    "print(f'Tiempo de entrenamiento por iteración: {str(round((end - start) / iterations, 2))} segundos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entreno un modelo con todo el dataset nuevo Modelo 9 \n",
    "# Load the competition data\n",
    "comp_data = pd.read_csv(\"/Users/franciscofrustoalvarado/Desktop/TD_VI/TP2_TDVI/competition_data_7.csv\")\n",
    "comp_data[\"date\"] = pd.to_datetime(comp_data[\"date\"])\n",
    "\n",
    "# Split into training and evaluation samples\n",
    "train_data = comp_data[comp_data[\"ROW_ID\"].isna()]\n",
    "eval_data = comp_data[comp_data[\"ROW_ID\"].notna()]\n",
    "del comp_data\n",
    "gc.collect()\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_data.drop(columns=[\"conversion\", \"ROW_ID\"]).select_dtypes(include=['number','float']),\n",
    "    train_data[\"conversion\"],\n",
    "    test_size=0.1,  # Proporción para el conjunto de prueba\n",
    "    random_state=42  # Semilla aleatoria para reproducibilidad\n",
    ")\n",
    "del train_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7579620578446584, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=0.7297041792253138, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.021892166283765713, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=13, max_leaves=None,\n",
       "              min_child_weight=1.1724744683543746, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=784, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7579620578446584, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=0.7297041792253138, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.021892166283765713, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=13, max_leaves=None,\n",
       "              min_child_weight=1.1724744683543746, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=784, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7579620578446584, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
       "              gamma=0.7297041792253138, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.021892166283765713, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=13, max_leaves=None,\n",
       "              min_child_weight=1.1724744683543746, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=784, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "params = {'max_depth': 13,\n",
    "          'learning_rate': 0.021892166283765713,\n",
    "          'gamma': 0.7297041792253138,\n",
    "          'reg_lambda': 1.8656819555055764,        # Parámetro de regularización.\n",
    "          'subsample': 0.8630230443880356,          # Entre 0.5 y 1.\n",
    "          'min_child_weight': 1.1724744683543746,\n",
    "          'colsample_bytree': 0.7579620578446584, # Entre 0.75 y 1.\n",
    "          'n_estimators': 784\n",
    "         }\n",
    "\n",
    "\n",
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic', seed = 2345, eval_metric = 'auc', **params)\n",
    "clf_xgb.fit(X_train, y_train, eval_set = [(X_test, y_test)], verbose = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_data = eval_data.drop(columns=[\"conversion\"])\n",
    "eval_data = eval_data.select_dtypes(include=['number','float'])\n",
    "y_preds =clf_xgb.predict_proba(eval_data.drop(columns=[\"ROW_ID\"]))[:, cls.classes_ == 1].squeeze()\n",
    "\n",
    "# Make the submission file\n",
    "submission_df = pd.DataFrame({\"ROW_ID\": eval_data[\"ROW_ID\"], \"conversion\": y_preds})\n",
    "submission_df[\"ROW_ID\"] = submission_df[\"ROW_ID\"].astype(int)\n",
    "submission_df.to_csv(\"xgboost_model_9.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (2563256841.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[93], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(clf_xgb.score(eval_data.drop(columns=[\"ROW_ID\"], y_preds)))\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(eval_data.shape)\n",
    "# print(X_test.columns)\n",
    "# print(eval_data.columns)\n",
    "print(clf_xgb.score(eval_data.drop(columns=[\"ROW_ID\"]), y_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
